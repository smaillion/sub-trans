{"cells":[{"cell_type":"markdown","metadata":{"id":"JEiHVnECGtSD"},"source":["安装组件"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uSlINZZD9MDi","executionInfo":{"status":"ok","timestamp":1704300498520,"user_tz":-540,"elapsed":23127,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"}},"outputId":"9613dbd9-2e8f-4619-885d-055791d735b8"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","llmx 0.0.15a0 requires cohere, which is not installed.\n","llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mCollecting ffmpeg\n","  Downloading ffmpeg-1.4.tar.gz (5.1 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: ffmpeg\n","  Building wheel for ffmpeg (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ffmpeg: filename=ffmpeg-1.4-py3-none-any.whl size=6080 sha256=09c622c3880bb02213ea2a04727c940d1d8a8f227678039ed6d8fa7b6776e49c\n","  Stored in directory: /root/.cache/pip/wheels/8e/7a/69/cd6aeb83b126a7f04cbe7c9d929028dc52a6e7d525ff56003a\n","Successfully built ffmpeg\n","Installing collected packages: ffmpeg\n","Successfully installed ffmpeg-1.4\n"]}],"source":["! pip install git+https://github.com/openai/whisper.git -q\n","! pip install ffmpeg"]},{"cell_type":"markdown","metadata":{"id":"cruxv0IuGyWh"},"source":["连接GoogleDrive"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"N5rnEfif-BNq","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704222967427,"user_tz":-540,"elapsed":52940,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"}},"outputId":"40296dcd-2e54-4808-e118-d54f0b070fc9"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import os\n","drive.mount('/content/drive', force_remount=True)\n","root_dir = \"/content/drive/My Drive/\"\n","base_dir = root_dir + 'Translation/'"]},{"cell_type":"markdown","metadata":{"id":"M0lvRZ7qEIfK"},"source":["\n","设置Whisper模型\n"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"DkEaoPwqDCXf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704223066667,"user_tz":-540,"elapsed":99244,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"}},"outputId":"98bd5629-f576-47a8-daeb-e2130f804590"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]},{"output_type":"stream","name":"stderr","text":["100%|█████████████████████████████████████| 2.88G/2.88G [01:07<00:00, 46.0MiB/s]\n"]}],"source":["import whisper\n","import torch\n","device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","print(device)\n","model = whisper.load_model(\"large-v3\", device=device)"]},{"cell_type":"markdown","metadata":{"id":"4frZbOvPS06Q"},"source":["设置用户词典"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1704223493821,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"},"user_tz":-540},"id":"pMj2FT4hS0b3","outputId":"68041b94-2554-4c05-93f0-544662c07bd2"},"outputs":[{"output_type":"stream","name":"stdout","text":["hints_id [[23182, 105, 3203, 3503], [23182, 105], [18100, 9335, 6117, 3368], [18034, 6847, 231], [18034, 6847, 231, 20953, 16680, 23196, 12817, 32026], [17198, 238, 10256, 117, 26555, 94], [17198, 238, 10256, 117, 26555, 94]]\n","hints_bad_id [[9592, 102, 6847, 231, 20953, 16680, 23196, 12817, 32026], [9592, 102, 6847, 231, 15567], [18034, 32045, 20953, 16680, 23196, 12817, 32026]]\n"]}],"source":["import csv\n","whistper_prompt_path = os.path.join(base_dir, \"params\", \"whistper-prompt.csv\")\n","def process_csv(file_path):\n","    hints = []\n","    hints_bad = []\n","\n","    with open(file_path, mode='r', encoding='utf-8-sig') as csvfile:\n","        csvreader = csv.reader(csvfile)\n","        for row in csvreader:\n","            text, weight = row[0], int(row[1])\n","            if weight > 0:\n","                hints.extend([text] * weight)\n","            elif weight < 0:\n","                hints_bad.extend([text] * abs(weight))\n","\n","    return hints, hints_bad\n","\n","woptions = whisper.DecodingOptions(language=\"ja\", without_timestamps=True)\n","tokenizer = whisper.tokenizer.get_tokenizer(True, language=\"ja\", task=woptions.task)\n","\n","multiply_coef:float = 1.2#自分で重みの調整を設定\n","def create_hints(hints:list[str], hints_bad:list[str]) -> tuple[list[int], list[int]]:\n","  '''ヒントの単語リストを単語のIDの変換する'''\n","  hints_id:list[int] = []\n","  for hint in hints:\n","      hints_id.append(tokenizer.encode(hint))\n","\n","  hints_bad_id:list[int] = []\n","  for hint in hints_bad:\n","      hints_bad_id.append(tokenizer.encode(hint))\n","\n","  return hints_id, hints_bad_id\n","\n","hints_id, hints_bad_id = create_hints(process_csv(whistper_prompt_path))\n","print(\"hints_id\", hints_id)\n","print(\"hints_bad_id\", hints_bad_id)"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":264,"status":"ok","timestamp":1704223496534,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"},"user_tz":-540},"id":"tqlRIEz0cgan"},"outputs":[],"source":["import torch.nn.functional as F\n","from torch import Tensor\n","from torch.distributions import Categorical\n","\n","def update(self, tokens: Tensor, logits: Tensor, sum_logprobs: Tensor) -> tuple[Tensor, bool]:\n","    def update_logits(hints_id, multiply_coef):\n","        for hint_ids in hints_id:\n","            reverse_hint_ids = hint_ids[::-1]\n","            for i, hint_id in enumerate(reverse_hint_ids):\n","                skip = False\n","                for y, previous_id in enumerate(reverse_hint_ids[i+1:]):\n","                    if tokens[0][-(y+1)] != previous_id:\n","                        skip=True\n","                        break\n","                if not skip:\n","                    logits[0][hint_id] *= multiply_coef\n","                    break\n","\n","    update_logits(hints_id, multiply_coef)\n","    update_logits(hints_bad_id, 1/multiply_coef)\n","\n","    if self.temperature == 0:\n","        next_tokens = logits.argmax(dim=-1)\n","    else:\n","        next_tokens = Categorical(logits=logits / self.temperature).sample()\n","\n","    logprobs = F.log_softmax(logits.float(), dim=-1)\n","    current_logprobs = logprobs[torch.arange(logprobs.shape[0]), next_tokens]\n","    sum_logprobs += current_logprobs * (tokens[:, -1] != self.eot)\n","\n","    next_tokens[tokens[:, -1] == self.eot] = self.eot\n","    tokens = torch.cat([tokens, next_tokens[:, None]], dim=-1)\n","\n","    completed = (tokens[:, -1] == self.eot).all()\n","    return tokens, completed\n","\n","whisper.decoding.GreedyDecoder.update = update#既存の関数を変更"]},{"cell_type":"markdown","metadata":{"id":"JNjmgBsTG6Ap"},"source":["执行Speach2Text"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":92977,"status":"ok","timestamp":1704223592534,"user":{"displayName":"ライオン（Lion）","userId":"03503095217066098183"},"user_tz":-540},"id":"YWGYuTea9XOB","outputId":"2cb3a5a6-1777-4676-81eb-4a738b35ad99"},"outputs":[{"output_type":"stream","name":"stderr","text":["<>:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","<>:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","100%|██████████| 30230/30230 [01:09<00:00, 435.22frames/s]\n","<ipython-input-12-d386ddd8a30a>:22: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n","  segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] is ' ' else text}\\n\\n\"\n"]}],"source":["from datetime import timedelta\n","\n","file_name = \"岬なこのそんなこんなこラジオ！第8回 おまけ.mp4\"\n","file_path = str(os.path.join(base_dir, \"RawVideo\", file_name))\n","\n","model = whisper.load_model(\"large-v3\", device=device)\n","result = model.transcribe(audio=file_path,\n","              verbose=False,\n","              language='ja',\n","              temperature=0.5,\n","              condition_on_previous_text=True,\n","              initial_prompt='岬なこのそんなこんなこラジオ',\n","              no_speech_threshold=0.9)\n","segments = result['segments']\n","\n","for segment in segments:\n","    startTime = str(0)+str(timedelta(seconds=int(segment['start'])))+',000'\n","    endTime = str(0)+str(timedelta(seconds=int(segment['end'])))+',000'\n","    text = segment['text']\n","    segmentId = segment['id']+1\n","    segment = f\"{segmentId}\\n{startTime} --> {endTime}\\n{text[1:] if text[0] is ' ' else text}\\n\\n\"\n","\n","    srtFilename = os.path.join(base_dir, \"output\", f\"{file_name}.srt\")\n","    with open(srtFilename, 'a', encoding='utf-8') as srtFile:\n","        srtFile.write(segment)"]},{"cell_type":"markdown","metadata":{"id":"AI-1NvK2HWOy"},"source":["更新翻译用户词典"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8gg41-lBg2b7"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fr3uNP9Vg7hN"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"bnSh06qeg8Iz"},"source":["翻译"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v4ZPR45dgmMl"},"outputs":[],"source":["import re\n","\n","\n","# DeepL API配置\n","api_key = \"\"  # 替换为你的API密钥\n","# headers = {\n","#     \"Authorization\": f\"Bearer {api_key}\",\n","#     \"Content-Type\": \"application/json\",\n","# }\n","\n","# 用户词典\n","\n","\n","def translate_with_context(text, context):\n","\n","    return result\n","\n","def main(input_file_path, output_file_path):\n","    with open(input_file_path, 'r', encoding='utf-8') as infile:\n","        lines = infile.readlines()\n","\n","    total_lines = len(lines)  # 获取总行数\n","\n","    with open(output_file_path, 'w', encoding='utf-8') as outfile:\n","        context_lines = []  # 存储最近的10行\n","\n","        for index, line in enumerate(lines):\n","            # 显示进度\n","            print(f\"Progress: {index+1}/{total_lines} lines\", end='\\r')\n","\n","            # 确定行是时间轴还是对话\n","            if \"-->\" in line:\n","                outfile.write(line)  # 直接写入时间轴\n","                context_lines = []  # 重置上下文\n","            elif re.match(r\"^\\d+$\", line.strip()) or line.strip() == \"\":\n","                continue\n","\n","            else:\n","                # 检查用户词典\n","                for jp, cn in user_dictionary.items():\n","                    line = line.replace(jp, cn)\n","\n","                # 构建上下文\n","                context = \"\\n\".join(context_lines[-10:])  # 获取最近的10行作为上下文\n","\n","                # 翻译\n","                translated_line = translate_with_context(line, context)\n","                outfile.write(line + \" \" + translated_line + \"\\n\")\n","\n","                # 更新上下文\n","                context_lines.append(line)\n","\n","if __name__ == \"__main__\":\n","    input_srt_path = \"E:\\\\Temp\\\\年末总结\\\\Timeline 1.srt\"  # 输入文件路径\n","    output_srt_path = \"E:\\\\Temp\\\\年末总结\\\\test1.srt\"  # 输出文件路径\n","    main(input_srt_path, output_srt_path)\n"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPig0lAz6xgTxflowtdcAMV"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}